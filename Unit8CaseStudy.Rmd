---
title: 'Modeling Runners Times (update this title)'
author: "Dennis Murray, Jared Law, Julien Battaillard, Cory Nichols"
section: "MSDS 7333-403 - Quantifying the World - Case Study 4 (Unit 8)"
date: "March 6th, 2018"
output: 
  word_document:
    #reference_docx: word-styles-reference-01.docx
    fig_caption: yes
---

```{r load_libs, echo=FALSE, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggthemes)
library(scales)
library(rvest)
library(magrittr)
library(XML)
library(missForest)
library(maps)
```

```{r setup, echo=FALSE, include=FALSE}
dir <- "~/DataScience/SMU/QTW/Unit8/Unit8_CaseStudy/"
setwd(dir)
knitr::opts_knit$set(root.dir = dir)
knitr::opts_chunk$set(echo = FALSE)
```

```{r make, include=FALSE, cache=TRUE}
# get and clean data
source("src/make.R")
```

## Abstract

## Introduction

## Literature Review

## Methods

## Results

```{r analysis_prep, include=FALSE, echo=FALSE}
# DENNIS, THIS ENTIRE BLOCK HAS CHANGED, COPY/PASTE OVER OLD IMPUTATION
#Combine men and women.  One Dataframe to rule them all.
AllFinishers <- rbind(cbMen, cbWomen)

# did some google research here, these youngins are for real!!!
# the 8 year old is legitimate per running records
# lets change age to <= 7 to be NA, these contain zeros from the
# data cleansing as well as a few odd ages that dont make sense
# only 51 records to drop out of ~146K

AllFinishers <- AllFinishers %>% 
                  mutate(age, age = replace(age, age <= 7, NA))

# only one runner < 30
AllFinishers <- AllFinishers %>% 
                 mutate(runTime, runTime=replace(runTime, runTime <= 30, NA))

# how many did we null?, 52 total
length(which(is.na(AllFinishers)))

# clean up whitespace just because it's obnoxious
AllFinishers[,c("sex","name","home")] <- apply(AllFinishers[,c("sex", "name", "home")], 
                                              2, 
                                              trimws)
# get rid of NAs
AllFinishers <- AllFinishers[complete.cases(AllFinishers),]
# ready to rock
```


```{r eda, include=FALSE, echo=FALSE}
#detach(package:plyr, unload=TRUE)

#Engineer some new features
#Overall Place, Gender Place, Age Group/Gender close

AgeGroupLabels <- c("Under 19", "20-24", "25-29", "30-34", "35-39", "40-44", "45-49", "50-54", "55-59", "60-64", "65-69", "70-79", "80 and up")
AgeThresholds <- c(0, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, 69, 79, Inf)

AllFinishers <- AllFinishers %>% mutate(AgeGroup = cut(age, AgeThresholds, AgeGroupLabels)) %>%
  group_by(year)  %>% mutate(OverallPlace = rank(runTime, ties.method="first")) %>%
  group_by(year, sex) %>% mutate(GenderPlace = rank(runTime, ties.method="first")) %>% 
  group_by(year, sex, AgeGroup) %>%  mutate(AgeGroupPlace = rank(runTime, ties.method="first")) %>% data.frame()

```

From 1999 to 2012 the overall size of the race grew, and in fact more than doubled in size.  

```{r eda2, include=TRUE, echo=FALSE, fig.width=8.5, fig.height=4}
#What about Total Race Size?
AllFinishers %>% 
  group_by(year, sex) %>% 
    summarise(RunnerCount = n()) %>% 
      ggplot(aes(x=year, y=RunnerCount, color=sex)) + 
      geom_line(size=1) + theme_light() + 
      scale_color_manual(values=c("#4286f4", "#fc41e9")) + 
      theme(legend.position = "bottom") + 
      scale_y_continuous( "Total Runners") +ggtitle("")

AllFinishers %>% 
  group_by(year) %>% 
    summarise(RunnerCount=n())
```

While participation by men and women both grew substantially, participation women played the greatest role in the expansion of the field.  Women's participation comprised a minority, 42% of runners, but by 2012 had exchanged positions with men at 57.5% of all participants.  

```{r eda3, include=TRUE, echo=FALSE, fig.width=8.5, fig.height=4}
#Have participants ages changed signfiicantly?
AllFinishers %>%  
  ggplot(aes(x=as.factor(year), y=age, color=sex)) + 
  geom_boxplot() + theme_light() + 
  scale_color_manual(values=c("#4286f4", "#fc41e9")) + 
  theme(legend.position = "none") + 
  scale_y_continuous("Age") +ggtitle("") + 
  scale_x_discrete("Year") + 
  ggtitle("Distribution of Age for Runners, 1999-2012") + 
  facet_wrap(~sex, ncol=1)
```

The age of male runners has declined since 1999, with an average age of 40.3 in 1999, declining to 37.8 in 2008, and stabilizing between 37 and 38 years of age since 2008.  The standard deviation of mens' ages has consistently been between 10 and 12 years.

Women participating in the race, however, have been consistently averaging between an average of 33 and 36 years old, without any consistent trend year over year. Standard deviation of age for women is about 9 years.

The finish time for the best male participant for this ten mile event have improved consistently from 2008 to 2012, with times approaching 45 minutes.  Womens' times have been more static, with the exception of a 4 year run of times from 2004 to 2007.  

```{r eda4, include = TRUE, echo = FALSE, fig.width=8.5, fig.height=4}
# needs GenderPlace
AllFinishers %>% 
  filter(GenderPlace==1) %>% 
    mutate(year=as.factor(year)) %>%
      ggplot(aes(x=year, y=runTime, group=sex, color=sex)) + 
      geom_point() + geom_line() + theme_light() + 
      scale_color_manual(values=c("#4286f4", "#fc41e9")) + 
      theme(legend.position = "bottom") + 
      scale_y_continuous("Time In Minutes") + 
      ggtitle("Fastest Time By Race Year, by Gender")
```

Examination of the race finish times by the age groups of the race, and by gender, show several general consistencies.  The first is the consistency in most age groups from year to year of the race.  Most age groups can be described as a "random walk" around some median race time, with the exception of the 20-24 year segment for men showing a consistent reduction of race finishing times year over year.  The Under 19 segment shows a high degree of variation in the winning runner's time.  Some degree of this variability might be explained by the number of participants in the segment - consistently less than 100 in each gender - as well as progression of these runners into the more elite 20-24 age group.  The two age divisions for ages 65 and over are omitted from the visualization.

```{r eda5, include = TRUE, echo = FALSE, fig.width =8.5, fig.height=4}
# needs AgeGroupPlace
AllFinishers %>% 
  filter(AgeGroupPlace==1) %>% 
    mutate(year=as.factor(year)) %>% 
      filter(age<=64 & age != 0) %>%
        ggplot(aes(x=year, y=runTime, group=sex, color=sex)) + 
        geom_point() + 
        geom_line( ) + 
        theme_light() + 
        scale_color_manual(values=c("#4286f4", "#fc41e9")) + 
        facet_wrap(~AgeGroup, ncol=5) + 
        theme(legend.position="bottom") + 
        scale_x_discrete(labels=c())
```
Examination of this series of visualizations also allows an inference to the relationship of a runner's age to his finishing time that we will examine in greater detail.  The visualization includes the fastest running time for every age between 20 and 80, for each race between 1999 and 2012.  Excluding the youngest, and the oldest participants from our research, the running times seem to follow a pattern for men of peak performance in the early twenties, with steadily increasing times for the rest of life, and more steeply increasing times and slower performances from age 60 to 80.  Women seem to peak closer to thirty, with times slowing through their thirties and fourties and experiencing an earlier degradation in performance and a steepening curve through their fifties and beyond.

```{r eda6, include = TRUE, echo = FALSE, fig.height=4, fig.width=8.5}
TopFinisher <- AllFinishers %>% 
                group_by(age, sex, year) %>% 
                  mutate(BestInAgeTime = min(runTime), WorstInAgeGroup = max(runTime)) 

BestTimeYr <- AllFinishers %>% 
                group_by(age, sex, year) %>% 
                  summarise(BestInAgeTime = min(runTime))

BestTimeYr %>% 
  ggplot(aes(x=age, y=BestInAgeTime, group=sex, color=sex)) + 
  geom_point(alpha=0.3) + 
  theme_light() + 
  scale_color_manual(values=c("#4286f4", "#fc41e9")) + 
  facet_wrap(~sex) + geom_smooth(method="loess") + 
  theme(legend.position = "bottom") + 
  ggtitle("Fastest Time by Age by Gender, 1999-2012") + 
  scale_x_continuous(limits=c(20,80)) + 
  scale_y_continuous("Best Performance by Age, 1999-2012")
```

``` {r LOESS_analysis_setup}

# add in un-normalized best times
#AllFinishers <- AllFinishers %>% 
#                    group_by(age, sex) %>% 
#                     mutate(BestInAgeTime = min(runTime)) 

# split base datasets for gender analysis purposes
AllFinishersM <- AllFinishers[AllFinishers$sex == "M",]
AllFinishersW <- AllFinishers[AllFinishers$sex == "W",]

# get best times for both men and women to use in LOESS smoothing
BestTimes <- AllFinishers %>%
             group_by(sex, age) %>%
             summarise(fastest=min(runTime))

BestTimesM <- BestTimes[BestTimes$sex == "M",]
BestTimesW <- BestTimes[BestTimes$sex == "W",]
```

``` {r men_1999v2012 fig.width=8.5, fig.height=4}

# use span of 0.5 instead of .75 to capture curvature better
RunModelMen <- loess(fastest ~ age, data=BestTimesM, span=0.5)
# smooth times out, returns vector of times for each age, use all ages
PredictedTimeM <- predict(RunModelMen, newdata = BestTimesM$age)


# plot fastest times by age - leaving all ages in right now

BestTimesM %>% ggplot(aes(x=age, y=fastest, group=sex, color=sex)) + geom_line() + theme_light() + ggtitle("Fastest Male Race Time Across 1999-2012") + scale_x_continuous("Age") + scale_y_continuous("Run Time in Minutes") + geom_smooth(method = "loess") + scale_color_manual(values = c("#4286f4"))

#plot(BestTimesM$fastest ~ BestTimesM$age, type ="l", xlim = c(20, 80))
# smooth out fastest times
#lines(x = BestTimesM$age, y = PredictedTimeM, col = "purple", lwd = 2)

```


```{r fig.width=8.5, fig.height=4}


# normalize all times based on fastest time predictions per instructions
names(PredictedTimeM) = BestTimesM$age
timeNormM = AllFinishersM$runTime / PredictedTimeM[as.character(AllFinishersM$age)]

# pull out two years we are interested in for the men
time99NormM = timeNormM[AllFinishersM$year == 1999]
time12NormM = timeNormM[AllFinishersM$year == 2012]

# 1999 age normalized times faster across all quartiles
summary(time99NormM)
summary(time12NormM)

# Visualize Men for 1999 v 2012
# feel free to change these vizzes up

# density plot called for in assignment
# this plots the normalized time percentages (e.g. 1.4 * 100 = 140)
# for better understanding (e.g. men in 1999 are ~160% of world record time for
# all age groups)
par(mfrow=c(2,1))
plot(density(100*time99NormM, na.rm = TRUE), 
    # ylim = c(0, 0.05), 
     col = "purple",
     lwd = 3,  xlab = "Time (percentage)",
     main = "Time Distribution for Male Runners
            Percentage of the Fastest Runner for a Given Age",
     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)
lines(density(100*time12NormM, na.rm = TRUE), 
          lwd = 3, col = "green")

legend("topleft", fill = c("purple", "green"),
       legend = c("1999", "2012"), bty = "n", cex=0.8)



AllNormTimes<-data.frame(age=names(time99NormM), year="1999", NormRunTime=time99NormM)
AllNormTimes<-rbind(AllNormTimes, data.frame(age=names(time12NormM), year="2012", NormRunTime=time12NormM))


AllNormTimes %>% ggplot(aes(x=NormRunTime, color=year, group=year)) + geom_density(size=1) + theme_light() + theme(legend.position = "bottom") + ggtitle("Density of Normalized Run Time - Men, 1999 vs. 2012", subtitle = "Run Times Normalized to Fastest Time by Age over All Race Years")

```
Reviewing the density plot, the 1999 is shown to be centered just above 1.5 times the fastest runner's time for the respective age group.  2012 is centered closer to 1.75 times the fastest runner's time.  2012 also exhibits a wider, flatter curve with a less prominent median normalized run time.

```{r fig.width=8.5, fig.height=4}




# 2012 age controlled times are definitely slower, 
# runners generally ran slower for their age grps

# check QQ plot for 1999 vs 2012 Men
qqplot(time99NormM, time12NormM, pch = 19, cex = 0.5, 
       xlab = "Age Normalized Time - 1999",
       ylab = "Age Normalized Time - 2012", 
       main = "QQ Plot: Run Time Normalized Performance for Men",
       cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)
abline(a =0, b = 1, col="red", lwd = 2)
par(mfrow=c(1,1))

# mode of distributions for 1999 peak earlier than 2012
# also tighter spread of times, indicates 1999 faster when
# considering age based times
# qq plot shows distributions are not normal, pull toward 2012
# indicating higher times in 2012 based on age

# distributions roughly normal for men, ok for t test
hist(time99NormM)
hist(time12NormM)

AllNormTimes %>% ggplot(aes(x=NormRunTime)) + geom_histogram() + theme_light() + facet_wrap(~year) + scale_x_continuous("Normalized Run Time") + ggtitle("Histogram of Normalized Mens' Run Times, 1999 vs. 2012")

# t test show sig difference with 1999 being faster when accounting for age
t.test(time99NormM, time12NormM)

```
Again, as mentioned in the exploration, the number of runners in the 2012 race overall has increased significantly, but we also see a clear shift towards a larger median - moving from about 1.5 times the best run time for the runner's respective age, to 1.75 times the best run time for the runner's age.  This might signal that the growth of the race's field is mostly in the recreational category of runner - a casual athlete, as well as persons seeking to walk the race route.  The second statement seems well supported by the long tail distribution of 2012 runners.  In 1999, the race effectively cut-off at the 2.5 times best runner's time, while in 2012 the race extended beyond three times the best runner's time. 

``` {r women_1999v2012 fig.width = 8.5, fig.height=4}
#i'M GOING TO DROP IN SAME VIZ FOR WOMEN LATER...it's the same code, just need to change it slightly
# use span of 0.5 instead of .75 to capture curvature better
RunModelWomen <- loess(fastest ~ age, data=BestTimesW, span=0.5)
# smooth times out, returns vector of times for each age
PredictedTimeW <- predict(RunModelWomen, newdata = BestTimesW$age)

# plot fastest times by age - leaving all ages in right now
# big spike in later ages
plot(BestTimesW$fastest ~ BestTimesW$age, type ="l", xlim = c(20, 80))
# smooth out fastest times
lines(x = BestTimesW$age, y = PredictedTimeW, col = "purple", lwd = 2)

BestTimesW %>% ggplot(aes(x=age, y=fastest, group=sex, color=sex)) + geom_line() + theme_light() + ggtitle("Fastest Female Race Time Across 1999-2012") + scale_x_continuous("Age") + scale_y_continuous("Run Time in Minutes") + geom_smooth(method = "loess") + scale_color_manual(values = c("#fc41e9")) + theme(legend.position = "bottom")


# normalize all times based on fastest time predictions per instructions
names(PredictedTimeW) = BestTimesW$age
timeNormW = AllFinishersW$runTime / PredictedTimeW[as.character(AllFinishersW$age)]

# pull out two times we are interested in for the women
time99NormW = timeNormW[AllFinishersW$year == 1999]
time12NormW = timeNormW[AllFinishersW$year == 2012]

# relatively similar, with slightly faster times in general in 99
# especially when considering slower age based times, large gap in 3Q
# more extreme slow times in 2012
summary(time99NormW)
summary(time12NormW)

# feel free to change these vizzes up

par(mfrow=c(2,1))
plot(density(100*time99NormW, na.rm = TRUE), 
    # ylim = c(0, 0.05), 
     col = "purple",
     lwd = 3,  xlab = "Time (percentage)",
     main = "Time Distribution for Women
            Percentage of the Fastest Runner for a Given Age",
     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)

lines(density(100*time12NormW, na.rm = TRUE), 
          lwd = 3, col = "green")

legend("topleft", fill = c("purple", "green"),
       legend = c("1999", "2012"), bty = "n",
       cex= 0.8)

AllNormTimes<-data.frame(age=names(time99NormW), year="1999", NormRunTime=time99NormW)
AllNormTimes<-rbind(AllNormTimes, data.frame(age=names(time12NormW), year="2012", NormRunTime=time12NormW))


AllNormTimes %>% ggplot(aes(x=NormRunTime, color=year, group=year)) + geom_density(size=1) + theme_light() + theme(legend.position = "bottom") + ggtitle("Density of Normalized Run Time - Women, 1999 vs. 2012", subtitle = "Run Times Normalized to Fastest Time by Age over All Race Years")


```
Women's times show less of a change from 1999 to 2012, but still exhibit some flattening of the center.  

```{r fig.width = 8.5, fig.height=4}


qqplot(time99NormW, time12NormW, pch = 19, cex = 0.5, 
       xlab = "Age Normalized Time - 1999",
       ylab = "Age Normalized Time - 2012", 
       main = "QQ Plot: Age Normalized Run Time for Women",
       cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)
abline(a =0, b = 1, col="red", lwd = 2)
par(mfrow=c(1,1))

# women's times are quite similar comparing two years, 
# however can see some pull for 2012 indicating slightly
# slower age controlled times, esp in 2012, indicated by the longer
# right tail in the density plot
# qq plot shows distributions are not normal, pull toward 2012
# indicating higher times in 2012 based on age

# distributions roughly normal
hist(time99NormW)
hist(time12NormW)

AllNormTimes %>% ggplot(aes(x=NormRunTime)) + geom_histogram() + theme_light() + facet_wrap(~year) + scale_x_continuous("Normalized Run Time") + ggtitle("Histogram of Normalized Womens' Run Times, 1999 vs. 2012")


# t test show sig difference with 1999 being faster when accounting for age
t.test(time99NormW, time12NormW)
```

The increase in the field size for women is dramatic, but interesting that in that it seems to exhibit more similarity in shape between 1999 and 2012.  

``` {r womenvmen_1999v2012 fig.width = 8.5, fig.height=4}
# COMPARE BOTH GENDERS

# Party like it's 1999 - compare normalized times between genders
# again, change these visualizations up if desired

par(mfrow=c(2,1))
plot(density(100*time99NormM, na.rm = TRUE), 
     ylim = c(0, 0.02), 
     col = "purple",
     lwd = 3,  xlab = "Time (percentage)",
     main = "Run Time Distribution for Male vs Female Runners
             Percentage of the Fastest Runner for a Given Age",
     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)

lines(density(100*time99NormW, na.rm = TRUE), 
          lwd = 3, col = "green")

legend("topleft", fill = c("purple", "green"),
       legend = c("1999M", "1999W"), bty = "n",
       cex = 0.8)

qqplot(time99NormM, time99NormW, pch = 19, cex = 0.5, 
       xlab = "Age Normalized Time - Men",
       ylab = "Age Normalized Time - Women", 
       main = "QQ Plot 1999: Men vs Women Normalized Times",
       cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)
abline(a =0, b = 1, col="red", lwd = 2)
par(mfrow=c(1,1))

# men age controlled outperform women in 99
t.test(time99NormM, time99NormW)


# now for 2012 comparisons

par(mfrow=c(2,1))
plot(density(100*time12NormM, na.rm = TRUE), 
     ylim = c(0, 0.02), 
     col = "purple",
     lwd = 3, 
     xlab = "Time (percentage)",
     main = "Run Time Distribution for Male vs Female Runners
             Percentage of the Fastest Runner for a Given Age",
     cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)

lines(density(100*time12NormW, na.rm = TRUE), 
          lwd = 3, col = "green")
legend("topleft", fill = c("purple", "green"),
       legend = c("2012M", "2012W"), bty = "n",
       cex = 0.8)

qqplot(time12NormM, time12NormW, pch = 19, cex = 0.5, 
       xlab = "Age Normalized Time - Men",
       ylab = "Age Normalized Time - Women", 
       main = "QQ Plot 2012: Men vs Women Normalized Times",
       cex.main = 0.8, cex.lab = 0.8, cex.axis = 0.8)
abline(a =0, b = 1, col="red", lwd = 2)

# much closer for 12, but men slightly outperform
t.test(time12NormM, time12NormW)


# reset All_Predicted based on new analysis methods above
AllPredicted <- rbind(data.frame(time = PredictedTimeW, sex="W", 
                                 age=as.numeric(names(PredictedTimeW))),  
                      data.frame(time=PredictedTimeM, sex="M", 
                                 age=as.numeric(names(PredictedTimeM))))

AllPredicted %>% ggplot(aes(x=age, y=time, group=sex, color=sex)) + 
  geom_line(size=1.1) + theme_light() + 
  scale_color_manual(values=c( "#fc41e9", "#4286f4")) + 
  facet_wrap(~sex) + ggtitle("LOESS Predicted Run Times By Age By Gender") + 
  scale_x_continuous("Age") + 
  scale_y_continuous("Predicted Time in Minutes") + 
  theme(legend.position = "bottom")

```

``` {r dennis_analysis}
# commented taken care of above
#PredictionsMen <- data.frame(ages, PredictedTime, as.character("M"))
#colnames(PredictionsMen) <- c("age", "PredictedTime", "sex")

#ages<- c(20:80)

#WomensTimes <- BestTime %>% filter(sex=="W")

#RunModelWomen <- loess(BestInAgeTime ~ age, data=WomensTimes)

#PredictedTimeWomens <- predict(RunModelWomen, newdata = ages)
#PredictionsWomen <- data.frame(ages, PredictedTimeWomens, as.character("W"))
#colnames(PredictionsWomen) <- c("age", "PredictedTime", "sex")

# fixed up this piece to work with above
# use normalization method from source
FinishersWithPredicted <- inner_join(AllFinishers, AllPredicted, by=c("age", "sex")) %>%    
                             mutate(NormalizedTime = runTime/time)

FinishersWithPredicted %>% 
  filter(year %in% c(1999, 2012)) %>% 
   ggplot(aes(x=age, NormalizedTime, color=sex, group=sex)) + 
   geom_point(alpha=0.15) + theme_light() + facet_grid(sex~year) +                               
   scale_color_manual(values=c("#4286f4", "#fc41e9")) + 
   theme(legend.position = "bottom") + 
   scale_y_continuous("Time Normalized to Predicted Fastest Time")

```


## Future Work and Conclusions
Application of predictive timing in running and other endurance sports holds numerous applications.

The running community holds the integrity of their sport in highest regard.  This has spurred a cottage industry of people who attempt to expose persons who may be taking unethical steps to improve their race times.  This varies from persons not following the selected course (either via a cut through or non-foot transportation), as well as people using surrogates carrying their bib to help qualify for prestigious races like the Boston Marathon.  Much of this research has been powered via the published results on race websites, as well as aggregator active.com.  The researchers have largely looked for suspicious results on a one-by-one basis, but a loess-based model based on age using multiple years results could lend new insight to questionable results.

Likewise, Race Organizers could benefit from deeper insight into their event for practical purposes.  Race organizers must first schedule road closures with municipal authorities to ensure a safe course for participants.  Understanding the age distribution, and the predicted finish times for their participants, might reduce the chances that a runner is not allowed to finish the race due to slow running times.  Additionally, race logistics like start waves are also dependent on expectation of the time required for a specific runner to finish the race.  While in most large races this is done on a seeding based n prior finishing times for the same distance, or expected finishing time based on other distances - unknown runners could be added to other groups based on a calculated race finishing time based on age.

Fitness devices, and smart phone applications for fitness have become a standard for recreational runners.  

## References


``` {r eda, include=FALSE}

# overplotting issues
plot(runTime ~ age, data = cbMen, ylim = c(40, 180),
     xlab = "Age (years)", ylab = "Run Time (minutes)")

# use color brewer to clean up overplotting
library(RColorBrewer)
ls("package:RColorBrewer")

# display help with colors
display.brewer.all()

Purples8 = brewer.pal(9, "Purples")[8]

# returns RBG hex
Purples8

# append alpha
Purples8A = paste(Purples8, "14", sep = "")

# plot with purple alpha, notice upward curbe in times as age increases
plot(runTime ~ jitter(age, amount = 0.5), 
     data = cbMen, 
     pch = 19, cex = 0.2, col = Purples8A,
     ylim = c(45, 165), xlim = c(15, 85),
     xlab = "Age (years)", ylab = "Run Time (minutes)")

# plot histogram
hist(cbMen$runTime)
library(e1071) 
skewness(cbMen$runTime) # right skew

# smooth density representation of scatter plot using color
# uses statistical techniques to building regions that vary by color
# color at (x,y) location is determined by density of points in a small region around the point
# average them, yields smoother plot with dark shades == high density

# represent dense data more efficiently:
smoothScatter(y = cbMen$runTime, x = cbMen$age,
              ylim = c(40, 165), xlim = c(15, 85),
              xlab = "Age (years)", ylab = "Run Time (minutes)")

# display summary statistics of run time for subgroups of runners with roughly same age
# remove outlier runners
cbMenSub = cbMen[cbMen$runTime > 30 &
                 !is.na(cbMen$age) & cbMen$age > 15
                 & cbMen$age != 0, ]

# cut data into different categories for ages (15 to 90 by 10s)
ageCat = cut(cbMenSub$age, breaks = c(seq(15, 75, 10), 90))
table(ageCat)

# can easily make out increases in time based on age!
plot(cbMenSub$runTime ~ ageCat, 
     xlab = "Age (years)", ylab = "Run Time (minutes)")

```

```{r lm_avg_performance, include=FALSE}

# fit a simple linear regression model
lmAge = lm(runTime ~ age, data = cbMenSub)

# positive coefficient for age as expected
lmAge$coefficients

# age is significant in the model, r squared is terrible, doesnt describe variance
# can see the line doesnt model 1Q and 3Q of data well, median is closer
summary(lmAge)

class(lmAge)

# we plot the residuals against age to see how this line fits
# can call residuals data from list returned via lmAge
smoothScatter(x = cbMenSub$age, y = lmAge$residuals,
              xlab = "Age (years)", ylab = "Residuals")
abline(h = 0, col = "purple", lwd = 3)
 
# fit locally weighted curve to the data to discern patterns
resid.lo = loess(resids ~ age, 
                 data = data.frame(resids = residuals(lmAge),
                                   age = cbMenSub$age))

# predict average residual for each year of age
age20to80 = 20:80

# predict locally fitted values from 20 to 80
resid.lo.pr = 
  predict(resid.lo, 
          newdata = data.frame(age = age20to80))

# plot LOESS predictions for residuals
# can easily see non-linear relationship as LOESS curves up as age increases
# lin reg does a poor job modeling curvature in runtime given age for older men
lines(x = age20to80, 
      y = resid.lo.pr, 
      col = "green", 
      lwd = 2)


# fitting a more complex model to predict runTime
# LOESS
menRes.lo = loess(runTime ~ age, cbMenSub)
menRes.lo.pr = predict(menRes.lo, data.frame(age = age20to80))

# Piecewise Linear Model with different segments
# allows us to bend the line at certain points
# hinge at 30,40,50,60

# consider one hinge at over 50
# coefficient c for over50 is change in slope from below 50 to above 50 and intercept makes segs
# connect
over50 = pmax(0, cbMenSub$age - 50) # zero out anything 50 and under and use this var in lm() call
lmOver50 = lm(runTime ~ age + over50, data = cbMenSub)

summary(lmOver50)

# create hingest
decades = seq(30, 60, by = 10)
# get a list of numeric vectors for each hinge for the piecewise regression equation
overAge = lapply(decades, 
                 function(x) pmax(0, (cbMenSub$age - x)))
names(overAge) = paste("over", decades, sep = "")
overAge = as.data.frame(overAge)
tail(overAge)

# now create piecewise model
lmPiecewise = lm(runTime ~ . , # include all covariates except for run time in DF
                 data = cbind(cbMenSub[, c("runTime", "age")], 
                              overAge)) # bind hinge variables

# over 60 not different from over 50
summary(lmPiecewise)

# how do we plot? use predict, but must set up data to fit model
overAge20 = lapply(decades, function(x) pmax(0, (age20to80 - x)))
names(overAge20) = paste("over", decades, sep = "")
overAgeDF = cbind(age = data.frame(age = age20to80), overAge20)

tail(overAgeDF)

predPiecewise = predict(lmPiecewise, overAgeDF)


# plot two methods against one another
plot(predPiecewise ~ age20to80,
     type = "l", col = "purple", lwd = 3,
     xlab = "Age (years)", ylab = "Run Time Prediction")

lines(x = age20to80, y = menRes.lo.pr, 
      col = "green", lty = 2, lwd = 3)

legend("topleft", col = c("purple", "green"),
       lty = c(1, 2), lwd= 3,
       legend = c("Piecewise Linear", "Loess Curve"), bty = "n")

# piecewise not able to capture over 70 because we didnt hinge on it

```

``` {r runner_composition, include=FALSE}
numRunners = with(cbMen, tapply(runTime, year, length))
# number of runners more than doubled from 1999 to 2012
plot(numRunners ~ names(numRunners), type="l", lwd = 2,
     xlab = "Years", ylab = "Number of Runners")


# look at summary stats from beginning and 2012
summary(cbMenSub$runTime[cbMenSub$year == 1999])
summary(cbMenSub$runTime[cbMenSub$year == 2012])


age1999 = cbMenSub[ cbMenSub$year == 1999, "age" ]
age2012 = cbMenSub[ cbMenSub$year == 2012, "age" ]

# plot density curves for ages in '99 and '12
# age distributions are definitely different
plot(density(age1999, na.rm = TRUE), 
     ylim = c(0, 0.05), col = "purple",
     lwd = 3,  xlab = "Age (years)",  main = "")

lines(density(age2012, na.rm = TRUE), 
      lwd = 3, lty = 2, col="green")

legend("topleft", col = c("purple", "green"), lty= 1:2, lwd = 3,
       legend = c("1999", "2012"), bty = "n")

# both sets did not come from the same distribution, line is not straight
# it's close but not exact
qqplot(age1999, age2012, pch = 19, cex = 0.5, 
       ylim = c(10,90), xlim = c(10,90), 
       xlab = "Age in 1999 Race",
       ylab = "Age in 2012 Race", 
       main = "Quantile-quantile plot of male runner's age")
abline(a =0, b = 1, col="red", lwd = 2)


# smooth curves (LOESS) for 99 and 12
mR.lo99 = loess(runTime ~ age, cbMenSub[ cbMenSub$year == 1999,])
mR.lo.pr99 = predict(mR.lo99, data.frame(age = age20to80))

mR.lo12 = loess(runTime ~ age, cbMenSub[ cbMenSub$year == 2012,])
mR.lo.pr12 = predict(mR.lo12, data.frame(age = age20to80))


plot(mR.lo.pr99 ~ age20to80,
     type = "l", col = "#984ea3", lwd = 3,
     xlab = "Age (years)", ylab = "Prediction (minutes)")  
lines(x = age20to80, y = mR.lo.pr12, col="#4daf4a", lty = 2, lwd = 3) 

legend("topleft", col = c("#984ea3", "#4daf4a"), lty = 1:2, lwd = 3,
       legend = c("1999", "2012"), bty = "n")


# plot differences in curves, 2012 was slower in general
gap14 = mR.lo.pr12 - mR.lo.pr99

plot(gap14 ~ age20to80, type = "l" , xlab = "Age (years)", 
     ylab = "Difference in Fitted Curves (minutes)", lwd = 2)
```

``` {r case_analysis, include=FALSE}
# EXTRA CREDIT
# imputation with random forest missForest
# replace ages < 10, 10M is for 13 and up, likely errors

# impute instead of toss out, take different approach than authors
# Lidiya Grigoryeva is an example

all_runners <- rbind(cbMen, cbWomen)

# did some google research here, these youngins are for real!!!
# lets change age to <=5, 
all_runners <- all_runners %>% 
                mutate(age, 
                 age=replace(age, age <= 5, NA))

# only one runner < 30, but let's impute
all_runners <- all_runners %>% 
                mutate(runTime, 
                 runTime=replace(runTime, runTime <= 30, NA))

# shuffle
all_runners <- all_runners[sample(nrow(all_runners)),]

# which did we null out for age?
nulls <- which(is.na(all_runners$age))

# clean up whitespace just because it's obnoxious
all_runners[,c("sex","name","home")] <- apply(all_runners[,c("sex", "name", "home")], 
                                              2, 
                                              trimws)

     
# prep for imputation, if we really wanted to get sexy here we 
# could cut VAR on country, obvious indicator for runTime and age, tried this and countries are MESSY
# dont have enough time to complete this extra task + that extra task 
all_runners_imp <- all_runners[,c("age","runTime", "year","sex")]

# this doesnt matter unless we do agg analysis including women
# call binary indicator to speed up imputation process a bit
all_runners_imp <- all_runners_imp %>% 
                   mutate(sex = ifelse(sex == "W", 1, 0 ))


# non parametric impute using random forest imputer
# reduce number of trees for time purposes, accuracy trade off not much diff
set.seed(42)
impute_object <- missForest(all_runners_imp, 
                            ntree = 50, 
                            maxiter = 3,
                            variablewise = FALSE,
                            verbose = FALSE)

# all numeric, small normalized RMSE
impute_object$OOBerror 

# get imputed features and round age predictions
all_runners_imp <- impute_object$ximp
all_runners_imp$age <- round(all_runners_imp$age)

# column bind other features not included in impute
# to re-create full data set
all_runners_imp <- cbind(all_runners[, c("sex","name","home")],
                         all_runners_imp[,-4] )

# what does imputation look like for age?
all_runners_imp[which(is.na(all_runners$age)),]

# separate men and women into imputed datasets for analysis
cbMen_imp = all_runners_imp[all_runners_imp$sex=="M",]
cbWomen_imp = all_runners_imp[all_runners_imp$sex=="W",]

# start men's analysis
fastestMen = tapply(cbMen_imp$runTime, 
                    cbMen_imp$age,
                    min, 
                    na.rm = FALSE) # we imputed here instead

# convert to numeric
age_fastest_men = as.numeric(names(fastestMen))
# smooth fastest times by fitting and predicting LOESS
# reduce LOESS span, get significant curve up in age
# consider kids < 12 yrs old
table(cbMen_imp$age) # too few obs when considering < 12 and > 80

mens_fast_lfit = loess(fastestMen ~ age_fastest_men, span=0.5)
mens_fast_lpred = predict(mens_fast_lfit, data.frame(age = age_fastest_men), se = FALSE)
plot(fastestMen ~ names(fastestMen), type ="l", xlim = c(20, 80))
lines(x = age_fastest_men, y = mens_fast_lpred, col = "purple", lwd = 2)

# normalize times - index on cbMen$age
# ensure predictions match ages
names(mens_fast_lpred) = age_fastest_men

# normalize times
timeNorm_m = cbMen_imp$runTime / mens_fast_lpred[as.character(cbMen_imp$age)]
time99Norm_m = timeNorm_m[cbMen_imp$year == 1999]
time12Norm_m = timeNorm_m[cbMen_imp$year == 2012]

# 1999 age normalized times faster across all quartiles
summary(time99Norm_m)
summary(time12Norm_m)

t.test()

par(mfrow=c(1,2))
plot(density(100*time99Norm_m, na.rm = TRUE), 
    # ylim = c(0, 0.05), 
     col = "purple",
     lwd = 3,  xlab = "Time (percentage)",
     main = "Time Normalized Distribution \n 1999 & 2012 Runners",
     cex.main = 0.8)
lines(density(100*time12Norm_m, na.rm = TRUE), 
          lwd = 3, col = "green")
legend("topleft", fill = c("purple", "green"),
       legend = c("1999", "2012"), bty = "n")

# 2012 age controlled times are definitely slower, 
# runners generally ran slower for their age grps
qqplot(time99Norm_m, time12Norm_m, pch = 19, cex = 0.5, 
       xlab = "Time in 1999 Race",
       ylab = "Time in 2012 Race", 
       main = "QQ Plot of Time Normalized Performance",
       cex.main = 0.8)
abline(a =0, b = 1, col="red", lwd = 2)

# mode of distributions for 1999 peak earlier than 2012
# also tighter spread of times, indicates 1999 faster when
# considering age based times
# qq plot shows distributions are not normal, pull toward 2012
# indicating higher times in 2012 based on age

# for the women

fastestWomen = tapply(cbWomen_imp$runTime, 
                      cbWomen_imp$age,
                      min, 
                      na.rm = FALSE) # we imputed here instead


# convert to numeric
age_fastest_women = as.numeric(names(fastestWomen))
# smooth fastest times by fitting and predicting LOESS
women_fast_lfit = loess(fastestWomen ~ age_fastest_women, span = 0.25)
women_fast_lpred = predict(women_fast_lfit, data.frame(age = age_fastest_women), se = FALSE)
plot(fastestWomen ~ names(fastestWomen), type ="l", xlim = c(20, 80))
lines(x = age_fastest_women, y = women_fast_lpred, col = "purple", lwd = 2)

# normalize times - index on cbWomen$age
# ensure predictions match ages
names(women_fast_lpred) = age_fastest_women
timeNorm_w = cbWomen_imp$runTime / women_fast_lpred[as.character(cbWomen_imp$age)]
time99Norm_w = timeNorm_w[cbWomen_imp$year == 1999]
time12Norm_w = timeNorm_w[cbWomen_imp$year == 2012]

summary(time99Norm_w)
summary(time12Norm_w)

plot(density(100*time99Norm_w, na.rm = TRUE), 
    # ylim = c(0, 0.05), 
     col = "purple",
     lwd = 3,  xlab = "Time (percentage)",
     main = "Time Distribution for 1999 and 2012 Runners\n Percentage of the fastest runner for that age")
lines(density(100*time12Norm_w, na.rm = TRUE), 
          lwd = 3, col = "green")
legend("topleft", fill = c("purple", "green"),
       legend = c("1999", "2012"), bty = "n")

# 2012 age controlled times are definitely slower, 
# runners generally ran slower for their age grps
qqplot(time99Norm_w, time12Norm_w, pch = 19, cex = 0.5, 
       xlab = "Age Normalized Time in 1999 Race",
       ylab = "Age Normalized Time in 2012 Race", 
       main = "Quantile-quantile plot of female runner's performance")
abline(a = 0, b = 1, col="red", lwd = 2)


# COMPARE BOTH GENDERS




```


``` {r following_runners, include=FALSE}
#this iterates over a character vector to eliminate beginning blanks, trailing blanks
# and then replace > 1 middle blanks with a single blank

cbMenSub <- cbMen

# clean name to start tracking
trimBlanks = function(charVector) {
  nameClean = gsub("^[[:blank:]]+", "", charVector)
  nameClean = gsub("[[:blank:]]+$", "", nameClean)
  nameClean = gsub("[[:blank:]]+", " ", nameClean)
}

# clean up name
nameClean = trimBlanks(cbMenSub$name)

length(nameClean)

# 43060 unique names, likely someone ran more than once (or we have a lot of the same names!)
length(unique(nameClean))


# cross tab name counts by nesting table()
table(table(nameClean))

# Michael Smith is the most frequent name (30 times!)
head(sort(table(nameClean), decreasing = TRUE), 1)

# let's look into Mr. Smith a bit more
mSmith = cbMenSub[nameClean == "Michael Smith", ]

head(unique(mSmith$home))

# clean up names a bit more
nameClean = tolower(nameClean)

# more Michael Smiths - 33
head( sort(table(nameClean), decreasing = TRUE), 1)

# get rid of extraneous commas and periods
nameClean = gsub("[,.]", "", nameClean)

# cross tab year and names
tabNameYr = table(cbMenSub$year, nameClean)

# 5 similar names in a single year
max(tabNameYr)

class(tabNameYr)

mode(tabNameYr)

names(attributes(tabNameYr))

dim(tabNameYr)

# colnames are the names of runners
head(colnames(tabNameYr), 3)

which( tabNameYr == max(tabNameYr) )

# find indices to get info on who shows up most for one year
which( tabNameYr == max(tabNameYr), arr.ind = TRUE )

indMax = which( tabNameYr == max(tabNameYr), arr.ind = TRUE )

# Michael Brown most common name
colnames(tabNameYr)[indMax[2]]

# add cleaned version of name to DF
cbMenSub$nameClean = nameClean


# approximate a year of birth
cbMenSub$yob = cbMenSub$year - cbMenSub$age

# Fix home in a similar way
homeClean = trimBlanks(tolower(cbMenSub$home))
cbMenSub$homeClean = gsub("[,.]", "", homeClean)

# lets use Michael Brown as an example
vars = c("year", "homeClean", "nameClean", "yob",  "runTime")
mb = which(nameClean == "michael brown") # get michael brown indices
birthOrder = order(cbMenSub$yob[mb]) # get order of birth given MB indices
cbMenSub[mb[birthOrder], vars] # filter df for michael brown based on birth order

# try a first pass of a unique idb by concatenating name and DOB 
cbMenSub$ID = paste(nameClean, cbMenSub$yob, sep = "_")

# how many times do each id appear?
races = tapply(cbMenSub$year, cbMenSub$ID, length)

races8 = names(races)[which(races >= 8)]

# get men with 8 or more races
men8 = cbMenSub[ cbMenSub$ID %in% races8, ]

orderByRunner = order(men8$ID, men8$year)
men8 = men8[orderByRunner, ] # reorder DF based on indices just obtained

# split up df by ID into a list of DFs
men8L = split(men8, men8$ID)
names(men8L) = races8

# how many runners do we have at least 8 obs for?
length(unique(men8$ID))


# we can discard matches if performance varies too much year to year
# there are A LOT of assumptions being made here
gapTime = tapply(men8$runTime, men8$ID,
                 function(t) any(abs(diff(t)) > 20))

gapTime = sapply(men8L, function(df) 
                          any(abs(diff(df$runTime)) > 20))

# 49 runners with gaps of 20m
sum(gapTime)

# get dfs for two runners from list of 8 or more events for runners
lapply(men8L[ gapTime ][1:2], function(df) df[, vars])

# add state into unique ID
homeLen = nchar(cbMenSub$homeClean)

cbMenSub$state = substr(cbMenSub$homeClean, 
                        start = homeLen - 1, stop = homeLen)

# set '06 to NA since no state
cbMenSub$state[cbMenSub$year == 2006] = NA

# reset id including state now
cbMenSub$ID = paste(cbMenSub$nameClean, cbMenSub$yob, 
                    cbMenSub$state, sep = "_")

numRaces = tapply(cbMenSub$year, cbMenSub$ID, length)
races8 = names(numRaces)[which(numRaces >= 8)]
men8 = cbMenSub[ cbMenSub$ID %in% races8, ]
orderByRunner = order(men8$ID, men8$year)
men8 = men8[orderByRunner, ]

# create list of DFs
men8L = split(men8, men8$ID)
names(men8L) = races8

length(races8)

```
``` {r following_runners_analysis, include=FALSE}

# set up plotting in a 3x3 grid
groups = 1 + (1:length(men8L) %% 9)

addRunners = function(listRunners, colors, numLty) 
{
  numRunners = length(listRunners)
  colIndx = 1 + (1:numRunners) %% length(colors) # assign colors modulus
  ltys = rep(1:numLty, each = length(colors), length = numRunners) # line types

  mapply(function(df, i) {      
           lines(df$runTime ~ df$age, 
           col = colors[colIndx[i]], lwd = 2, lty = ltys[i])
         }, listRunners, i = 1:numRunners) 
}

colors = c("#e41a1c", "#377eb8","#4daf4a", "#984ea3", 
           "#ff7f00", "#a65628")

# create blank plot, to add lines for each group
invisible(
  sapply(1:9, function(grpId){
    plot( x = 0, y = 0, type = "n",
          xlim = c(20, 80), ylim = c(50, 130),
          xlab = "Age (years)", ylab = "Run Time (minutes)")
     
    addRunners(men8L[ groups == grpId ], colors, numLty = 6) # add in plots
  }) )

# fit linear model to each
fitOne = function(oneRunner, addLine = FALSE, col = "grey") {
  lmOne = lm(runTime ~ age, data = oneRunner)
  if (addLine) 
    lines(x = oneRunner$age, y = predict(lmOne), 
          col = col, lwd = 2, lty = 2)

  ind = floor( (nrow(oneRunner) + 1) / 2)
  res = c(coefficients(lmOne)[2], oneRunner$age[ind],
          predict(lmOne)[ind])
  names(res) = c("ageCoeff", "medAge", "predRunTime")
  return(res)
}


plot( x = 0, y = 0, type = "n",
      xlim = c(20, 80), ylim = c(50, 130),
      xlab = "Age (years)", ylab = "Run Time (minutes)")
     
addRunners(men8L[ groups == 9 ], colors, numLty = 6)
lapply(men8L[groups == 9], fitOne, addLine = TRUE, col = "black")

men8LongFit = lapply(men8L, fitOne)

coeffs = sapply(men8LongFit, "[", "ageCoeff" )
ages = sapply(men8LongFit, "[", "medAge")

longCoeffs = lm(coeffs ~ ages)

summary(longCoeffs)

pdf("CB_LongCoeffs.pdf", width = 10, height = 7)
oldPar = par(mar = c(4.1, 4.1, 1, 1))
plot(coeffs ~ ages, xlab = "Median Age (years)",
     ylab = "Coefficient (minutes per race / year)")
abline(longCoeffs, col = "#984ea3", lwd = 3)
abline(h = 0, col="blue", lwd = 3)
loCoeffs = loess(coeffs ~ ages)
ageV = min(ages):max(ages)
predV = predict(loCoeffs, new = data.frame(ages = ageV))
lines(x = ageV, y = predV, lwd = 3, lty = 2, col = "#4daf4a")
par(oldPar)
dev.off()
```





# APPENDIX - BOOK CODE

```{r web_scraping, include=FALSE, echo=FALSE, eval=FALSE}
# Section 2.7 Parsing
#ubase = "http://www.cherryblossom.org/"
#url = paste(ubase, "results/2012/2012cucb10m-m.htm", sep = "")
#doc = htmlParse(url)

# use xpath to get all pre nodes, get nodeset returns a list of all <pre> nodes in a list
#preNode = getNodeSet(doc, "//pre")

# get text value from the node
#txt = xmlValue(preNode[[1]])

#nchar(txt)

# start and end of text
#substr(txt, 1, 50)

#substr(txt, nchar(txt) - 50, nchar(txt))

# split lines by carriage/new line
#els = strsplit(txt, "\\r\\n")[[1]]

# length of text
#length(els)

# first few lines are all header
#els[1:3]

#els[ length(els) ]

# formalize FUN to extract tables from pages for '99 to '12
# 28 pages in total (14 men + 14 women)
#extractResTable =
       # Retrieve data from web site, find preformatted text,
       # return as a character vector.
#function(url)
#{
#  doc = htmlParse(url)
#  preNode = getNodeSet(doc, "//pre")
#  txt = xmlValue(preNode[[1]])
#  
#  els = strsplit(txt, "\r\n")[[1]]
#  if(length(els) == 1){
#    els = strsplit(txt, "\n")[[1]]
#  }
  
#  return(els)
#}

#m2012 = extractResTable(url)

#identical(m2012, els)


# clean up var names, authors are terrible and causes confusion

#url_base = "http://www.cherryblossom.org/"

# get a list of urls from which to extract the data for men's results
#urls = paste(ubase, "results/", 1999:2012, "/",
#             1999:2012, "cucb10m-m.htm", sep = "")

# apply FUN to vector of URLs
#menTables = lapply(urls, extractResTable)

#options(error = recover)
#menTables = lapply(urls, extractResTable)

# these are for browing the recover() debugging mode
#Browse[1]> ls()

#Browse[1]> url

#Browse[1]> length(preNode)

# find that URLs are different depending on the year, great work web devs.


extractResTable =
  #
  # Retrieve data from web site, 
  # find the preformatted text,
  # and write lines or return as a character vector.
  #
  function(url = "http://www.cherryblossom.org/results/2009/09cucb-F.htm",
           year = 1999, sex = "male", file = NULL)
  {
    doc = htmlParse(url)

    if (year == 2000) {
      # Get preformatted text from 4th font element
      # The top file is ill formed so the <pre> search doesn't work.
      ff = getNodeSet(doc, "//font")
      txt = xmlValue(ff[[4]])
      els = strsplit(txt, "\r\n")[[1]]
    }
    
    else if (year == 2000 & sex == "female"){
      pres = getNodeSet(doc, "//p") # for bad HTML
      txt = xmlValue(pres[[1]])
      els = strsplit(txt, "\r\n")[[1]]
      
    }
    
    else if (year == 2009 & sex == "male") {
      # Get preformatted text from <div class="Section1"> element
      # Each line of results is in a <pre> element
      div1 = getNodeSet(doc, "//div[@class='Section1']")
      pres = getNodeSet(div1[[1]], "//pre")
      els = sapply(pres, xmlValue)
    }
    
    else {
      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els = strsplit(txt, "\r\n")[[1]]
      if(length(els) == 1){
                           els = strsplit(txt, "\n")[[1]]
      }
    } 
    
    if (is.null(file)) return(els)
    # Write the lines as a text file.
    writeLines(els, con = file)
  }
```

```{r data_munging, include=FALSE}
# Nolan and Temple Lang Ch. 2

url <- "http://www.cherryblossom.org"

# errors out
#m2012 = read.table(file="MenTxt/2012.txt", skip = 8)

els_2011 = readLines("Data/mens2011.txt")
els_2011[1:10]

# try readlines, as we need custom induction logic
# time in 2012 == Net Time
els_2012 = readLines("Data/mens2012.txt")
els_2012[1:10]

# grep to find "===="" starts, rows above it are headers, rows below are data
# get index of line that begins with at least three equal signs
eqIndex = grep("^===", els_2012)
eqIndex

# or using substr
first3 = substr(els_2012, 1, 3)
which(first3 == "===")

# extract the spacer row ("=== ====") and discard earlier rows
spacerRow = els_2012[eqIndex]
headerRow = els_2012[eqIndex - 1] # just spacer row index - 1
body = els_2012[ -(1:eqIndex) ] # get all except for 1 to spacer row

# format header row to lowercase
headerRow = tolower(headerRow)

# finding age: use regexpr to find index 
ageStart = regexpr("ag", headerRow)
ageStart
# begins at 49 and is two characters for the header label (49,50)

# use this index position to get age from body in a char vector
age = substr(body, start = ageStart, stop = ageStart + 1)
head(age)

# convert to numeric and get summary, median age is 35 for male runners in 2012, youngest is 9, 1 NA
summary(as.numeric(age))

# search spacer row for blank spaces to generalize this method instead of relying on header values
blankLocs = gregexpr(" ", spacerRow)
blankLocs
# blankLocs lists the blank locations between each "column" on the spacer row of "=== ===== ======"
# gregexpr searches for a group of matches (much like using () in a regular expression)
# we can use these positions to extract data and header values by determining start and end of columns

# handle the first column, place 0 into the vector to begin
searchLocs = c(0, blankLocs[[1]])

# use mapply() and substr to extract all the columns
# this method iterates over each line in the body
# mapply gives us a way to call a non-vectorized function in a vectorized way
# a great explanation: http://www.studytrails.com/r/core/control_structures_r_apply_functions_2/

values = mapply(substr,      # apply substr
                list(body),  # for each list item in body
                start = searchLocs[ -length(searchLocs)] + 1,   # for each item in start
                stop = searchLocs[ -1 ] - 1)                    # and each item in stop


# encapsulate finding column locations into a FUN
findColLocs = function(spacerRow) {

  spaceLocs = gregexpr(" ", spacerRow)[[1]] # find a group of column locs
  rowLength = nchar(spacerRow)

  if (substring(spacerRow, rowLength, rowLength) != " ")
    return( c(0, spaceLocs, rowLength + 1))
  else return(c(0, spaceLocs))
}

# create FUN to extract certain columns only, all of this is reliant on the spacer row (yikes)
# takes header row, column names, locations of blanks in separator row
selectCols = function(colNames, headerRow, searchLocs) 
{
  sapply(colNames, 
         function(name, headerRow, searchLocs) # for each name in col names
         {
           startPos = regexpr(name, headerRow)[[1]] # find position using regex
           if (startPos == -1) 
             return( c(NA, NA) ) # error catch
    
           index = sum(startPos >= searchLocs) # how many columns including and after?
           c(searchLocs[index] + 1, searchLocs[index + 1] - 1) # get column width as separate entries in a matrix
         },
         headerRow = headerRow, searchLocs = searchLocs ) # satiate the other function here, this is wasteful
}


searchLocs = findColLocs(spacerRow)
ageLoc = selectCols("ag", headerRow, searchLocs) # this function returns the index for the column in a matrix

# use ageLoc result to apply substr in a vectorized fashion (this can be expanded to include multi-columns)
ages = mapply(substr, 
              list(body), 
              start = ageLoc[1,], 
              stop = ageLoc[2, ])

summary(as.numeric(ages))

# now apply to multiple columns
shortColNames = c("name", "home", "ag", "gun", "net", "time")

locCols = selectCols(shortColNames, headerRow, searchLocs)
# call locCols and notice how gun time and net time are NA

values = mapply(substr, 
                list(body), 
                start = locCols[1, ], 
                stop = locCols[2, ])

class(values)

colnames(values) = shortColNames
head(values)

tail(values)[ , 1:3]

# roll all this mess up into a function for modularity
extractVariables = 
function(file, varNames =c("name", "home", "ag", "gun", "net", "time"))
{
  # Find the index of the spacer row with =s
  eqIndex = grep("^===", file)
  
  # Extract the two key rows and the data
  spacerRow = file[eqIndex] 
  headerRow = tolower(file[ eqIndex - 1 ])
  body = file[ -(1 : eqIndex) ]
       
  # Obtain the starting and ending positions of variables
  searchLocs = findColLocs(spacerRow)
  locCols = selectCols(varNames, headerRow, searchLocs)

  values = mapply(substr, 
                  list(body), 
                  start = locCols[1, ], 
                  stop = locCols[2, ])
  
  colnames(values) = varNames
  
  invisible(values)
}

mfilenames = paste("Data/mens", 1999:2012, ".txt", sep = "")
menFiles = lapply(mfilenames, readLines)
names(menFiles) = 1999:2012
sapply(menFiles, length) # check to see if this worked.....

menResMat = lapply(menFiles, extractVariables)
length(menResMat) # 14, good
sapply(menResMat, nrow)  # some nulls fell out but overall data intact

wfilenames = paste("Data/womens", 1999:2012, ".txt", sep = "")
womenFiles = lapply(wfilenames, readLines)
names(womenFiles) = 1999:2012
sapply(womenFiles, length) # readLines worked

# errors out because of missing data in 2001 file!
# womenResMat = lapply(womenFiles, extractVariables)

### The 2001 results for women are missing the === and the column names.
### Can we pick it up from the 2001 men? YES! Make an exercise
#wfilenames = paste("WomenTxt/", 1999:2012, ".txt", sep = "")
#womenTables = lapply(wfilenames, readLines)

# lets append some context... 
womenFiles[[3]] = append(womenFiles[[3]], menFiles[[3]][4:5], after=3)

womenResMat = lapply(womenFiles, extractVariables)
length(womenResMat) # 14, good
sapply(womenResMat, nrow)  # some nulls fell out but overall data intact
```

```{r data_cleaning, include=FALSE}
# ADJUSTED AND PART OF MAKE FILE
# keep track of year and sex, clean variables

# use as.numeric to convert age ('ag') in the 2012 matrix
age = as.numeric(menResMat[['2012']][ , 'ag'])
tail(age)

# apply over each matrix, warnings introduced for NAs coerced
age = sapply(menResMat,
             function(x) as.numeric(x[ , 'ag']))




# 2003 and 2006 are wrong, 2003 median age is ~3 years old
# 2006 has first quartile of 3-4 year olds....

#pdf("Images/CB_BoxplotAgeByYr.pdf", width = 8, height = 5)
#oldPar = par(mar = c(4.1, 4.1, 1, 1))
boxplot(age, ylab = "Age", xlab = "Year")
#par(oldPar)
#dev.off()

#age values shifted right one space outside of our respective spacer row boundaries!
head(menFiles[['2003']])

# in 2006, spacing is off to rigt in multiple columns
menFiles[['2006']][2200:2205]


# solve by including blank position
selectCols = function(shortColNames, headerRow, searchLocs) {
  sapply(shortColNames, function(shortName, headerRow, searchLocs){
    startPos = regexpr(shortName, headerRow)[[1]]
    
    if (startPos == -1) return( c(NA, NA) )
    
    index = sum(startPos >= searchLocs)
    c(searchLocs[index] + 1, searchLocs[index + 1]) # get rid of the -1 in the second term
  }, 
  
  headerRow = headerRow, searchLocs = searchLocs )
}

# check to see if this made a difference
menResMat = lapply(menFiles, extractVariables)
#womenResMat = lapply(womenFiles, extractVariables)

# still seeing NAs
age = sapply(menResMat, 
             function(x) as.numeric(x[ , 'ag']))

# much better from an age perspective
# boxplot with mens age first fix after adjusted searchLocs
boxplot(age, ylab = "Age", xlab = "Year")

# now take care of NAs, count for each matrix
sapply(age,  function(x) sum(is.na(x)))

# investigate the 61 NAs in 2001
age2001 = age[["2001"]]

# explore original raw files, we dropped header in our latet file, so need to add index back in to offset
grep("^===", menFiles[['2001']])

badAgeIndex = which(is.na(age2001)) + 5
menFiles[['2001']][ badAgeIndex ]

# scattered throughout file
badAgeIndex

extractVariables = 
function(file, varNames =c("name", "home", "ag", "gun",
                           "net", "time"))
{
  
  # Find the index of the row with =s
  eqIndex = grep("^===", file)
  # Extract the two key rows and the data 
  spacerRow = file[eqIndex] 
  headerRow = tolower(file[ eqIndex - 1 ])
  body = file[ -(1 : eqIndex) ]
  # Remove footnotes and blank rows
  footnotes = grep("^[[:blank:]]*(\\*|\\#)", body)
  if ( length(footnotes) > 0 ) body = body[ -footnotes ]
  blanks = grep("^[[:blank:]]*$", body)
  if (length(blanks) > 0 ) body = body[ -blanks ]
  
  
  # Obtain the starting and ending positions of variables   
  searchLocs = findColLocs(spacerRow)
  locCols = selectCols(varNames, headerRow, searchLocs)
  
  Values = mapply(substr, list(body), start = locCols[1, ], 
                  stop = locCols[2, ])
  colnames(Values) = varNames
  
  return(Values)
}

menResMat = lapply(menFiles, extractVariables)
#womenResMat = lapply(womenFiles, extractVariables)

# address minimum age issues in 2001, 2002 and 2003
which(age2001 < 5)

# find lines corresponding to the indices, age shows zero, hold for analysis
menFiles[['2001']][ which(age2001 < 5) + 5 ]


# time variable creation
charTime = menResMat[['2012']][, 'time']
head(charTime, 5)

tail(charTime, 5)

# use str split on colons to piece them up
timePieces = strsplit(charTime, ":")

timePieces[[1]]

tail(timePieces, 1)

timePieces = sapply(timePieces, as.numeric)

# report time in minutes
runTime = sapply(timePieces, 
                 function(x) {
                   if (length(x) == 2) x[1] + x[2]/60
                   else 60*x[1] + x[2] + x[3]/60
                 })

summary(runTime)

# encapsulte into converTime
convertTime = function(time) {
  timePieces = strsplit(time, ":")
  timePieces = sapply(timePieces, as.numeric)
  sapply(timePieces, function(x) {
                      if (length(x) == 2) x[1] + x[2]/60
                      else 60*x[1] + x[2] + x[3]/60
                      })
}

# create final dataframe for analysis

createDF = 
function(Res, year, sex) 
{
  # Determine which time to use
  useTime = if( !is.na(Res[1, 'net']) )  
              Res[ , 'net']
            else if( !is.na(Res[1, 'gun']) ) 
               Res[ , 'gun']
            else 
               Res[ , 'time']

  # convert time to minutes
  runTime = convertTime(useTime)
  
  Results = data.frame(year = rep(year, nrow(Res)), # fill year into df
                       sex = rep(sex, nrow(Res)), # fill sex into df
                       name = Res[ , 'name'],
                       home = Res[ , 'home'],
                       age = as.numeric(Res[, 'ag']), 
                       runTime = runTime,
                       stringsAsFactors = FALSE)
  invisible(Results)
}

# create men's DF from each matrix
#menDF = mapply(createDF, menResMat, year = 1999:2012,
#               sex = rep("M", 14), SIMPLIFY = FALSE)
# more Nas from time being coerced to NA
#warnings()[ c(1:2, 49:50) ]

sapply(menDF, function(x) sum(is.na(x$runTime)))


# adjust for footnotes in run time and blanks
createDF = function(Res, year, sex) 
{
  # Determine which time to use
  if ( !is.na(Res[1, 'net']) ) useTime = Res[ , 'net']
  else if ( !is.na(Res[1, 'gun']) ) useTime = Res[ , 'gun']
  else useTime = Res[ , 'time']
  
  # Remove # and * and blanks from time
  useTime = gsub("[#\\*[:blank:]]", "", useTime)
  runTime = convertTime(useTime[ useTime != "" ])
  
  # Drop rows with no time
  Res = Res[ useTime != "", ]
  #if(sex=='W'){
  #  
  #  age = gsub("   ", "0  ", Res[,'ag'])
  #  age = gsub("XX "," 0 ", age)
  #  
  #  Res[, 'ag'] = age
  #}
  
  Results = data.frame(year = rep(year, nrow(Res)),
                       sex = rep(sex, nrow(Res)),
                       name = Res[ , 'name'], home = Res[ , 'home'],
                       age = as.numeric(Res[, 'ag']), 
                       runTime = runTime,
                       stringsAsFactors = FALSE)
  invisible(Results)
}

# still a lot of NAs from 2006 with incorrect spacer row!
#menDF = mapply(createDF, menResMat, year = 1999:2012,
#               sex = rep("M", 14), SIMPLIFY = FALSE)

#sapply(menDF, function(x) sum(is.na(x$runTime)))

# FIX 2006
separatorIdx = grep("^===", menFiles[["2006"]])
separatorRow = menFiles[['2006']][separatorIdx]
separatorRowX = paste(substring(separatorRow, 1, 63), " ", 
                      substring(separatorRow, 65, nchar(separatorRow)), 
                      sep = "")
menFiles[['2006']][separatorIdx] = separatorRowX

# FINALLY good to go
menResMat = sapply(menFiles, extractVariables)
menDF = mapply(createDF, menResMat, year = 1999:2012,
               sex = rep("M", 14), SIMPLIFY = FALSE)


# clean 2006 file with bad separator for women as well
separatorIdx = grep("^===", womenFiles[["2006"]])
separatorRow = womenFiles[['2006']][separatorIdx]
separatorRowX = paste(substring(separatorRow, 1, 63), " ", 
                      substring(separatorRow, 65, nchar(separatorRow)), 
                      sep = "")
womenFiles[['2006']][separatorIdx] = separatorRowX

womenResMat = sapply(womenFiles, extractVariables)

# women files have issues with ages of "XX" and "   ", adjusted previous create DF for this issue
womenDF = mapply(createDF, womenResMat, year = 1999:2012,
                 sex = rep("W", 14), SIMPLIFY = FALSE)

# womens files have some missing ages being coerced to NA. 
# Let's fix and insert zeros and take care of later in analysis
# initial analysis shows one age of XX in women's files, need to clean this as well
# implemented in createDF above
# lapply(womenDF, function(x) {x[!complete.cases(x),] })
# sapply(womenResMat, function(x){ sum(x[,'ag'] == "   ")})
# womenResMat[[4]][3261,]


#pdf("CB_BoxplotTimeByYr.pdf", width = 8, height = 5)
boxplot(sapply(menDF, function(x) x$runTime), 
        xlab = "Year", ylab = "Run Time (min)")
#dev.off()

cbMen = do.call(rbind, menDF)
save(cbMen, file = "cbMen.rda")

dim(cbMen)

load("cbMen.rda")

pdf("CB_Overplot.pdf", width = 8, height = 6)
oldPar = par(mar = c(4.1, 4.1, 1, 1))

```
---
title: 'Modeling Runners Times (update this title)'
author: "Dennis Murray, Jared Law, Julien Battaillard, Cory Nichols"
section: "MSDS 7333-403 - Quantifying the World - Case Study 4 (Unit 8)"
date: "March 6th, 2018"
output: 
  word_document:
    #reference_docx: word-styles-reference-01.docx
    fig_caption: yes
---

```{r load_libs, echo=FALSE, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(rvest)
library(magrittr)
library(XML)
```

```{r setup, echo=FALSE, include=FALSE}
dir <- "~/DataScience/SMU/QTW/Unit8/Unit8_CaseStudy/"
setwd(dir)
knitr::opts_knit$set(root.dir = dir)
knitr::opts_chunk$set(echo = FALSE)
```

```{r make, include=FALSE, cache=TRUE}
# get and clean data
source("src/make.R")
```

## Abstract

## Introduction

## Literature Review

## Methods

## Results

## Future Work and Conclusions

## References


``` {r eda, include=FALSE}

# overplotting issues
plot(runTime ~ age, data = cbMen, ylim = c(40, 180),
     xlab = "Age (years)", ylab = "Run Time (minutes)")

# use color brewer to clean up overplotting
library(RColorBrewer)
ls("package:RColorBrewer")

# display help with colors
display.brewer.all()

Purples8 = brewer.pal(9, "Purples")[8]

# returns RBG hex
Purples8

# append alpha
Purples8A = paste(Purples8, "14", sep = "")

# plot with purple alpha, notice upward curbe in times as age increases
plot(runTime ~ jitter(age, amount = 0.5), 
     data = cbMen, 
     pch = 19, cex = 0.2, col = Purples8A,
     ylim = c(45, 165), xlim = c(15, 85),
     xlab = "Age (years)", ylab = "Run Time (minutes)")

# plot histogram
hist(cbMen$runTime)
library(e1071) 
skewness(cbMen$runTime) # right skew

# smooth density representation of scatter plot using color
# uses statistical techniques to building regions that vary by color
# color at (x,y) location is determined by density of points in a small region around the point
# average them, yields smoother plot with dark shades == high density

# represent dense data more efficiently:
smoothScatter(y = cbMen$runTime, x = cbMen$age,
              ylim = c(40, 165), xlim = c(15, 85),
              xlab = "Age (years)", ylab = "Run Time (minutes)")

# display summary statistics of run time for subgroups of runners with roughly same age
# remove outlier runners
cbMenSub = cbMen[cbMen$runTime > 30 &
                 !is.na(cbMen$age) & cbMen$age > 15
                 & cbMen$age != 0, ]

# cut data into different categories for ages (15 to 90 by 10s)
ageCat = cut(cbMenSub$age, breaks = c(seq(15, 75, 10), 90))
table(ageCat)

# can easily make out increases in time based on age!
plot(cbMenSub$runTime ~ ageCat, 
     xlab = "Age (years)", ylab = "Run Time (minutes)")

```

```{r lm_avg_performance, include=FALSE}

# fit a simple linear regression model
lmAge = lm(runTime ~ age, data = cbMenSub)

# positive coefficient for age as expected
lmAge$coefficients

# age is significant in the model, r squared is terrible, doesnt describe variance
# can see the line doesnt model 1Q and 3Q of data well, median is closer
summary(lmAge)

class(lmAge)

# we plot the residuals against age to see how this line fits
# can call residuals data from list returned via lmAge
smoothScatter(x = cbMenSub$age, y = lmAge$residuals,
              xlab = "Age (years)", ylab = "Residuals")
abline(h = 0, col = "purple", lwd = 3)
 
# fit locally weighted curve to the data to discern patterns
resid.lo = loess(resids ~ age, 
                 data = data.frame(resids = residuals(lmAge),
                                   age = cbMenSub$age))

# predict average residual for each year of age
age20to80 = 20:80

# predict locally fitted values from 20 to 80
resid.lo.pr = 
  predict(resid.lo, 
          newdata = data.frame(age = age20to80))

# plot LOESS predictions for residuals
# can easily see non-linear relationship as LOESS curves up as age increases
# lin reg does a poor job modeling curvature in runtime given age for older men
lines(x = age20to80, 
      y = resid.lo.pr, 
      col = "green", 
      lwd = 2)


# fitting a more complex model to predict runTime
# LOESS
menRes.lo = loess(runTime ~ age, cbMenSub)
menRes.lo.pr = predict(menRes.lo, data.frame(age = age20to80))

# Piecewise Linear Model with different segments
# allows us to bend the line at certain points
# hinge at 30,40,50,60

# consider one hinge at over 50
# coefficient c for over50 is change in slope from below 50 to above 50 and intercept makes segs
# connect
over50 = pmax(0, cbMenSub$age - 50) # zero out anything 50 and under and use this var in lm() call
lmOver50 = lm(runTime ~ age + over50, data = cbMenSub)

summary(lmOver50)

# create hingest
decades = seq(30, 60, by = 10)
# get a list of numeric vectors for each hinge for the piecewise regression equation
overAge = lapply(decades, 
                 function(x) pmax(0, (cbMenSub$age - x)))
names(overAge) = paste("over", decades, sep = "")
overAge = as.data.frame(overAge)
tail(overAge)

# now create piecewise model
lmPiecewise = lm(runTime ~ . , # include all covariates except for run time in DF
                 data = cbind(cbMenSub[, c("runTime", "age")], 
                              overAge)) # bind hinge variables

# over 60 not different from over 50
summary(lmPiecewise)

# how do we plot? use predict, but must set up data to fit model
overAge20 = lapply(decades, function(x) pmax(0, (age20to80 - x)))
names(overAge20) = paste("over", decades, sep = "")
overAgeDF = cbind(age = data.frame(age = age20to80), overAge20)

tail(overAgeDF)

predPiecewise = predict(lmPiecewise, overAgeDF)


# plot two methods against one another
plot(predPiecewise ~ age20to80,
     type = "l", col = "purple", lwd = 3,
     xlab = "Age (years)", ylab = "Run Time Prediction")

lines(x = age20to80, y = menRes.lo.pr, 
      col = "green", lty = 2, lwd = 3)

legend("topleft", col = c("purple", "green"),
       lty = c(1, 2), lwd= 3,
       legend = c("Piecewise Linear", "Loess Curve"), bty = "n")

# piecewise not able to capture over 70 because we didnt hinge on it

```

``` {r runner_composition, include=FALSE}
numRunners = with(cbMen, tapply(runTime, year, length))
# number of runners more than doubled from 1999 to 2012
plot(numRunners ~ names(numRunners), type="l", lwd = 2,
     xlab = "Years", ylab = "Number of Runners")


# look at summary stats from beginning and 2012
summary(cbMenSub$runTime[cbMenSub$year == 1999])
summary(cbMenSub$runTime[cbMenSub$year == 2012])


age1999 = cbMenSub[ cbMenSub$year == 1999, "age" ]
age2012 = cbMenSub[ cbMenSub$year == 2012, "age" ]

# plot density curves for ages in '99 and '12
# age distributions are definitely different
plot(density(age1999, na.rm = TRUE), 
     ylim = c(0, 0.05), col = "purple",
     lwd = 3,  xlab = "Age (years)",  main = "")

lines(density(age2012, na.rm = TRUE), 
      lwd = 3, lty = 2, col="green")

legend("topleft", col = c("purple", "green"), lty= 1:2, lwd = 3,
       legend = c("1999", "2012"), bty = "n")

# both sets did not come from the same distribution, line is not straight
# it's close but not exact
qqplot(age1999, age2012, pch = 19, cex = 0.5, 
       ylim = c(10,90), xlim = c(10,90), 
       xlab = "Age in 1999 Race",
       ylab = "Age in 2012 Race", 
       main = "Quantile-quantile plot of male runner's age")
abline(a =0, b = 1, col="red", lwd = 2)


# smooth curves (LOESS) for 99 and 12
mR.lo99 = loess(runTime ~ age, cbMenSub[ cbMenSub$year == 1999,])
mR.lo.pr99 = predict(mR.lo99, data.frame(age = age20to80))

mR.lo12 = loess(runTime ~ age, cbMenSub[ cbMenSub$year == 2012,])
mR.lo.pr12 = predict(mR.lo12, data.frame(age = age20to80))


plot(mR.lo.pr99 ~ age20to80,
     type = "l", col = "#984ea3", lwd = 3,
     xlab = "Age (years)", ylab = "Prediction (minutes)")  
lines(x = age20to80, y = mR.lo.pr12, col="#4daf4a", lty = 2, lwd = 3) 

legend("topleft", col = c("#984ea3", "#4daf4a"), lty = 1:2, lwd = 3,
       legend = c("1999", "2012"), bty = "n")


# plot differences in curves, 2012 was slower in general
gap14 = mR.lo.pr12 - mR.lo.pr99

plot(gap14 ~ age20to80, type = "l" , xlab = "Age (years)", 
     ylab = "Difference in Fitted Curves (minutes)", lwd = 2)

# this is our assignment LOL - age grading
fastestMan = tapply(cbMen$runTime, cbMen$age, min, na.rm = TRUE)
# one outlier at 1.5 - Peter Hui, had different format
# fix
fastestMan[67] = 66.53
plot(fastestMan ~ names(fastestMan), type ="l", xlim = c(20, 80))
ageFM = as.numeric(names(fastestMan))
mR.loF = loess(fastestMan ~ ageFM)
mR.lo.prF = predict(mR.loF, data.frame(age = ageFM), se = FALSE)
lines(x = ageFM, y = mR.lo.prF, col = "purple", lwd = 2)


timeNorm =cbMen$runTime / mR.lo.prF[as.character(cbMen$age)]
time99Norm = timeNorm[menRes$year == 1999]
time12Norm = timeNorm[menRes$year == 2012]
summary(time99Norm)

summary(time12Norm)

plot(density(100*time99Norm, na.rm = TRUE), 
    # ylim = c(0, 0.05), 
     col = "purple",
     lwd = 3,  xlab = "Time (percentage)",
     main = "Time Distribution for 1999 and 2012 Runners\n Percentage of the fastest runner for that age")
lines(density(100*time12Norm, na.rm = TRUE), 
          lwd = 3, col = "green")
legend("topleft", fill = c("purple", "green"),
       legend = c("1999", "2012"), bty = "n")

```

``` {r following_runners, include=FALSE}
trimBlanks = function(charVector) {
  nameClean = gsub("^[[:blank:]]+", "", charVector)
  nameClean = gsub("[[:blank:]]+$", "", nameClean)
  nameClean = gsub("[[:blank:]]+", " ", nameClean)
}

nameClean = trimBlanks(cbMenSub$name)

length(nameClean)

length(unique(nameClean))

table(table(nameClean))

head( sort(table(nameClean), decreasing = TRUE), 1)

mSmith = cbMenSub[nameClean == "Michael Smith", ]

head(unique(mSmith$home))

nameClean = tolower(nameClean)

head( sort(table(nameClean), decreasing = TRUE), 1)

nameClean = gsub("[,.]", "", nameClean)

tabNameYr = table(cbMenSub$year, nameClean)

max(tabNameYr)

class(tabNameYr)

mode(tabNameYr)

names(attributes(tabNameYr))

dim(tabNameYr)

head(colnames(tabNameYr), 3)

which( tabNameYr == max(tabNameYr) )

which( tabNameYr == max(tabNameYr), arr.ind = TRUE )

indMax = which( tabNameYr == max(tabNameYr), arr.ind = TRUE )
colnames(tabNameYr)[indMax[2]]

cbMenSub$nameClean = nameClean

cbMenSub$yob = cbMenSub$year - cbMenSub$age

# Fix home in a similar way
homeClean = trimBlanks(tolower(cbMenSub$home))
cbMenSub$homeClean = gsub("[,.]", "", homeClean)

vars = c("year", "homeClean", "nameClean", "yob",  "runTime")
mb = which(nameClean == "michael brown")
birthOrder = order(cbMenSub$yob[mb])
cbMenSub[mb[birthOrder], vars]

cbMenSub$ID = paste(nameClean, cbMenSub$yob, sep = "_")

races = tapply(cbMenSub$year, cbMenSub$ID, length)

races8 = names(races)[which(races >= 8)]

men8 = cbMenSub[ cbMenSub$ID %in% races8, ]

orderByRunner = order(men8$ID, men8$year)
men8 = men8[orderByRunner, ]

men8L = split(men8, men8$ID)
names(men8L) = races8

length(unique(men8$ID))

gapTime = tapply(men8$runTime, men8$ID,
                 function(t) any(abs(diff(t)) > 20))

gapTime = sapply(men8L, function(df) 
                          any(abs(diff(df$runTime)) > 20))

sum(gapTime)

lapply(men8L[ gapTime ][1:2], function(df) df[, vars])

homeLen = nchar(cbMenSub$homeClean)

cbMenSub$state = substr(cbMenSub$homeClean, 
                        start = homeLen - 1, stop = homeLen)

cbMenSub$state[cbMenSub$year == 2006] = NA

cbMenSub$ID = paste(cbMenSub$nameClean, cbMenSub$yob, 
                    cbMenSub$state, sep = "_")

numRaces = tapply(cbMenSub$year, cbMenSub$ID, length)
races8 = names(numRaces)[which(numRaces >= 8)]
men8 = cbMenSub[ cbMenSub$ID %in% races8, ]
orderByRunner = order(men8$ID, men8$year)
men8 = men8[orderByRunner, ]

men8L = split(men8, men8$ID)
names(men8L) = races8

length(races8)

groups = 1 + (1:length(men8L) %% 9)

addRunners = function(listRunners, colors, numLty) 
{
  numRunners = length(listRunners)
  colIndx = 1 + (1:numRunners) %% length(colors)
  ltys = rep(1:numLty, each = length(colors), length = numRunners)

  mapply(function(df, i) {      
           lines(df$runTime ~ df$age, 
           col = colors[colIndx[i]], lwd = 2, lty = ltys[i])
         }, listRunners, i = 1:numRunners) 
}

colors = c("#e41a1c", "#377eb8","#4daf4a", "#984ea3", 
           "#ff7f00", "#a65628")
par(mfrow = c(3, 3), mar = c(2, 2, 1, 1))
invisible(
  sapply(1:9, function(grpId){
    plot( x = 0, y = 0, type = "n",
          xlim = c(20, 80), ylim = c(50, 130),
          xlab = "Age (years)", ylab = "Run Time (minutes)")
     
    addRunners(men8L[ groups == grpId ], colors, numLty = 6)
  }) )

fitOne = function(oneRunner, addLine = FALSE, col = "grey") {
  lmOne = lm(runTime ~ age, data = oneRunner)
  if (addLine) 
    lines(x = oneRunner$age, y = predict(lmOne), 
          col = col, lwd = 2, lty = 2)

  ind = floor( (nrow(oneRunner) + 1) / 2)
  res = c(coefficients(lmOne)[2], oneRunner$age[ind],
          predict(lmOne)[ind])
  names(res) = c("ageCoeff", "medAge", "predRunTime")
  return(res)
}

par(mfrow = c(1, 1), mar = c(5, 4, 1, 1))

plot( x = 0, y = 0, type = "n",
      xlim = c(20, 80), ylim = c(50, 130),
      xlab = "Age (years)", ylab = "Run Time (minutes)")
     
addRunners(men8L[ groups == 9 ], colors, numLty = 6)
lapply(men8L[groups == 9], fitOne, addLine = TRUE, col = "black")

men8LongFit = lapply(men8L, fitOne)

coeffs = sapply(men8LongFit, "[", "ageCoeff" )
ages = sapply(men8LongFit, "[", "medAge")

longCoeffs = lm(coeffs ~ ages)

summary(longCoeffs)

pdf("CB_LongCoeffs.pdf", width = 10, height = 7)
oldPar = par(mar = c(4.1, 4.1, 1, 1))
plot(coeffs ~ ages, xlab = "Median Age (years)",
     ylab = "Coefficient (minutes per race / year)")
abline(longCoeffs, col = "#984ea3", lwd = 3)
abline(h = 0, col="blue", lwd = 3)
loCoeffs = loess(coeffs ~ ages)
ageV = min(ages):max(ages)
predV = predict(loCoeffs, new = data.frame(ages = ageV))
lines(x = ageV, y = predV, lwd = 3, lty = 2, col = "#4daf4a")
par(oldPar)
dev.off()
```


```{r}
#scrape some data
#Really long url of a JSON of race results for 2017:
"http://results.xacte.com/json/search?eventId=1410&callback=jQuery183009502051809510115_1519067795323&sEcho=1&iColumns=13&sColumns=&iDisplayStart=0&iDisplayLength=10&mDataProp_0=&mDataProp_1=bib&mDataProp_2=firstname&mDataProp_3=lastname&mDataProp_4=sex&mDataProp_5=age&mDataProp_6=city&mDataProp_7=state&mDataProp_8=country&mDataProp_9=&mDataProp_10=&mDataProp_11=&mDataProp_12=&sSearch=&bRegex=false&sSearch_0=&bRegex_0=false&bSearchable_0=false&sSearch_1=&bRegex_1=false&bSearchable_1=true&sSearch_2=&bRegex_2=false&bSearchable_2=true&sSearch_3=&bRegex_3=false&bSearchable_3=true&sSearch_4=&bRegex_4=false&bSearchable_4=true&sSearch_5=&bRegex_5=false&bSearchable_5=true&sSearch_6=&bRegex_6=false&bSearchable_6=true&sSearch_7=&bRegex_7=false&bSearchable_7=true&sSearch_8=&bRegex_8=false&bSearchable_8=true&sSearch_9=&bRegex_9=false&bSearchable_9=true&sSearch_10=&bRegex_10=false&bSearchable_10=true&sSearch_11=&bRegex_11=false&bSearchable_11=false&sSearch_12=&bRegex_12=false&bSearchable_12=false&iSortCol_0=0&sSortDir_0=asc&iSortingCols=1&bSortable_0=false&bSortable_1=true&bSortable_2=true&bSortable_3=true&bSortable_4=true&bSortable_5=true&bSortable_6=true&bSortable_7=true&bSortable_8=true&bSortable_9=false&bSortable_10=false&bSortable_11=false&bSortable_12=false&_=1519067795588"


```


```{r}
#viz it up

```


```{r}
#Come to a statistical conclusion and call this shit DONE

```



# APPENDIX - BOOK CODE

```{r web_scraping, include=FALSE, echo=FALSE, eval=FALSE}
# Section 2.7 Parsing
#ubase = "http://www.cherryblossom.org/"
#url = paste(ubase, "results/2012/2012cucb10m-m.htm", sep = "")
#doc = htmlParse(url)

# use xpath to get all pre nodes, get nodeset returns a list of all <pre> nodes in a list
#preNode = getNodeSet(doc, "//pre")

# get text value from the node
#txt = xmlValue(preNode[[1]])

#nchar(txt)

# start and end of text
#substr(txt, 1, 50)

#substr(txt, nchar(txt) - 50, nchar(txt))

# split lines by carriage/new line
#els = strsplit(txt, "\\r\\n")[[1]]

# length of text
#length(els)

# first few lines are all header
#els[1:3]

#els[ length(els) ]

# formalize FUN to extract tables from pages for '99 to '12
# 28 pages in total (14 men + 14 women)
#extractResTable =
       # Retrieve data from web site, find preformatted text,
       # return as a character vector.
#function(url)
#{
#  doc = htmlParse(url)
#  preNode = getNodeSet(doc, "//pre")
#  txt = xmlValue(preNode[[1]])
#  
#  els = strsplit(txt, "\r\n")[[1]]
#  if(length(els) == 1){
#    els = strsplit(txt, "\n")[[1]]
#  }
  
#  return(els)
#}

#m2012 = extractResTable(url)

#identical(m2012, els)


# clean up var names, authors are terrible and causes confusion

#url_base = "http://www.cherryblossom.org/"

# get a list of urls from which to extract the data for men's results
#urls = paste(ubase, "results/", 1999:2012, "/",
#             1999:2012, "cucb10m-m.htm", sep = "")

# apply FUN to vector of URLs
#menTables = lapply(urls, extractResTable)

#options(error = recover)
#menTables = lapply(urls, extractResTable)

# these are for browing the recover() debugging mode
#Browse[1]> ls()

#Browse[1]> url

#Browse[1]> length(preNode)

# find that URLs are different depending on the year, great work web devs.


extractResTable =
  #
  # Retrieve data from web site, 
  # find the preformatted text,
  # and write lines or return as a character vector.
  #
  function(url = "http://www.cherryblossom.org/results/2009/09cucb-F.htm",
           year = 1999, sex = "male", file = NULL)
  {
    doc = htmlParse(url)

    if (year == 2000) {
      # Get preformatted text from 4th font element
      # The top file is ill formed so the <pre> search doesn't work.
      ff = getNodeSet(doc, "//font")
      txt = xmlValue(ff[[4]])
      els = strsplit(txt, "\r\n")[[1]]
    }
    
    else if (year == 2000 & sex == "female"){
      pres = getNodeSet(doc, "//p") # for bad HTML
      txt = xmlValue(pres[[1]])
      els = strsplit(txt, "\r\n")[[1]]
      
    }
    
    else if (year == 2009 & sex == "male") {
      # Get preformatted text from <div class="Section1"> element
      # Each line of results is in a <pre> element
      div1 = getNodeSet(doc, "//div[@class='Section1']")
      pres = getNodeSet(div1[[1]], "//pre")
      els = sapply(pres, xmlValue)
    }
    
    else {
      # Get preformatted text from <pre> elements
      pres = getNodeSet(doc, "//pre")
      txt = xmlValue(pres[[1]])
      els = strsplit(txt, "\r\n")[[1]]
      if(length(els) == 1){
                           els = strsplit(txt, "\n")[[1]]
      }
    } 
    
    if (is.null(file)) return(els)
    # Write the lines as a text file.
    writeLines(els, con = file)
  }
```

```{r data_munging, include=FALSE}
# Nolan and Temple Lang Ch. 2

url <- "http://www.cherryblossom.org"

# errors out
#m2012 = read.table(file="MenTxt/2012.txt", skip = 8)

els_2011 = readLines("Data/mens2011.txt")
els_2011[1:10]

# try readlines, as we need custom induction logic
# time in 2012 == Net Time
els_2012 = readLines("Data/mens2012.txt")
els_2012[1:10]

# grep to find "===="" starts, rows above it are headers, rows below are data
# get index of line that begins with at least three equal signs
eqIndex = grep("^===", els_2012)
eqIndex

# or using substr
first3 = substr(els_2012, 1, 3)
which(first3 == "===")

# extract the spacer row ("=== ====") and discard earlier rows
spacerRow = els_2012[eqIndex]
headerRow = els_2012[eqIndex - 1] # just spacer row index - 1
body = els_2012[ -(1:eqIndex) ] # get all except for 1 to spacer row

# format header row to lowercase
headerRow = tolower(headerRow)

# finding age: use regexpr to find index 
ageStart = regexpr("ag", headerRow)
ageStart
# begins at 49 and is two characters for the header label (49,50)

# use this index position to get age from body in a char vector
age = substr(body, start = ageStart, stop = ageStart + 1)
head(age)

# convert to numeric and get summary, median age is 35 for male runners in 2012, youngest is 9, 1 NA
summary(as.numeric(age))

# search spacer row for blank spaces to generalize this method instead of relying on header values
blankLocs = gregexpr(" ", spacerRow)
blankLocs
# blankLocs lists the blank locations between each "column" on the spacer row of "=== ===== ======"
# gregexpr searches for a group of matches (much like using () in a regular expression)
# we can use these positions to extract data and header values by determining start and end of columns

# handle the first column, place 0 into the vector to begin
searchLocs = c(0, blankLocs[[1]])

# use mapply() and substr to extract all the columns
# this method iterates over each line in the body
# mapply gives us a way to call a non-vectorized function in a vectorized way
# a great explanation: http://www.studytrails.com/r/core/control_structures_r_apply_functions_2/

values = mapply(substr,      # apply substr
                list(body),  # for each list item in body
                start = searchLocs[ -length(searchLocs)] + 1,   # for each item in start
                stop = searchLocs[ -1 ] - 1)                    # and each item in stop


# encapsulate finding column locations into a FUN
findColLocs = function(spacerRow) {

  spaceLocs = gregexpr(" ", spacerRow)[[1]] # find a group of column locs
  rowLength = nchar(spacerRow)

  if (substring(spacerRow, rowLength, rowLength) != " ")
    return( c(0, spaceLocs, rowLength + 1))
  else return(c(0, spaceLocs))
}

# create FUN to extract certain columns only, all of this is reliant on the spacer row (yikes)
# takes header row, column names, locations of blanks in separator row
selectCols = function(colNames, headerRow, searchLocs) 
{
  sapply(colNames, 
         function(name, headerRow, searchLocs) # for each name in col names
         {
           startPos = regexpr(name, headerRow)[[1]] # find position using regex
           if (startPos == -1) 
             return( c(NA, NA) ) # error catch
    
           index = sum(startPos >= searchLocs) # how many columns including and after?
           c(searchLocs[index] + 1, searchLocs[index + 1] - 1) # get column width as separate entries in a matrix
         },
         headerRow = headerRow, searchLocs = searchLocs ) # satiate the other function here, this is wasteful
}


searchLocs = findColLocs(spacerRow)
ageLoc = selectCols("ag", headerRow, searchLocs) # this function returns the index for the column in a matrix

# use ageLoc result to apply substr in a vectorized fashion (this can be expanded to include multi-columns)
ages = mapply(substr, 
              list(body), 
              start = ageLoc[1,], 
              stop = ageLoc[2, ])

summary(as.numeric(ages))

# now apply to multiple columns
shortColNames = c("name", "home", "ag", "gun", "net", "time")

locCols = selectCols(shortColNames, headerRow, searchLocs)
# call locCols and notice how gun time and net time are NA

values = mapply(substr, 
                list(body), 
                start = locCols[1, ], 
                stop = locCols[2, ])

class(values)

colnames(values) = shortColNames
head(values)

tail(values)[ , 1:3]

# roll all this mess up into a function for modularity
extractVariables = 
function(file, varNames =c("name", "home", "ag", "gun", "net", "time"))
{
  # Find the index of the spacer row with =s
  eqIndex = grep("^===", file)
  
  # Extract the two key rows and the data
  spacerRow = file[eqIndex] 
  headerRow = tolower(file[ eqIndex - 1 ])
  body = file[ -(1 : eqIndex) ]
       
  # Obtain the starting and ending positions of variables
  searchLocs = findColLocs(spacerRow)
  locCols = selectCols(varNames, headerRow, searchLocs)

  values = mapply(substr, 
                  list(body), 
                  start = locCols[1, ], 
                  stop = locCols[2, ])
  
  colnames(values) = varNames
  
  invisible(values)
}

mfilenames = paste("Data/mens", 1999:2012, ".txt", sep = "")
menFiles = lapply(mfilenames, readLines)
names(menFiles) = 1999:2012
sapply(menFiles, length) # check to see if this worked.....

menResMat = lapply(menFiles, extractVariables)
length(menResMat) # 14, good
sapply(menResMat, nrow)  # some nulls fell out but overall data intact

wfilenames = paste("Data/womens", 1999:2012, ".txt", sep = "")
womenFiles = lapply(wfilenames, readLines)
names(womenFiles) = 1999:2012
sapply(womenFiles, length) # readLines worked

# errors out because of missing data in 2001 file!
# womenResMat = lapply(womenFiles, extractVariables)

### The 2001 results for women are missing the === and the column names.
### Can we pick it up from the 2001 men? YES! Make an exercise
#wfilenames = paste("WomenTxt/", 1999:2012, ".txt", sep = "")
#womenTables = lapply(wfilenames, readLines)

# lets append some context... 
womenFiles[[3]] = append(womenFiles[[3]], menFiles[[3]][4:5], after=3)

womenResMat = lapply(womenFiles, extractVariables)
length(womenResMat) # 14, good
sapply(womenResMat, nrow)  # some nulls fell out but overall data intact
```

```{r data_cleaning, include=FALSE}
# ADJUSTED AND PART OF MAKE FILE
# keep track of year and sex, clean variables

# use as.numeric to convert age ('ag') in the 2012 matrix
age = as.numeric(menResMat[['2012']][ , 'ag'])
tail(age)

# apply over each matrix, warnings introduced for NAs coerced
age = sapply(menResMat,
             function(x) as.numeric(x[ , 'ag']))




# 2003 and 2006 are wrong, 2003 median age is ~3 years old
# 2006 has first quartile of 3-4 year olds....

#pdf("Images/CB_BoxplotAgeByYr.pdf", width = 8, height = 5)
#oldPar = par(mar = c(4.1, 4.1, 1, 1))
boxplot(age, ylab = "Age", xlab = "Year")
#par(oldPar)
#dev.off()

#age values shifted right one space outside of our respective spacer row boundaries!
head(menFiles[['2003']])

# in 2006, spacing is off to rigt in multiple columns
menFiles[['2006']][2200:2205]


# solve by including blank position
selectCols = function(shortColNames, headerRow, searchLocs) {
  sapply(shortColNames, function(shortName, headerRow, searchLocs){
    startPos = regexpr(shortName, headerRow)[[1]]
    
    if (startPos == -1) return( c(NA, NA) )
    
    index = sum(startPos >= searchLocs)
    c(searchLocs[index] + 1, searchLocs[index + 1]) # get rid of the -1 in the second term
  }, 
  
  headerRow = headerRow, searchLocs = searchLocs )
}

# check to see if this made a difference
menResMat = lapply(menFiles, extractVariables)
#womenResMat = lapply(womenFiles, extractVariables)

# still seeing NAs
age = sapply(menResMat, 
             function(x) as.numeric(x[ , 'ag']))

# much better from an age perspective
# boxplot with mens age first fix after adjusted searchLocs
boxplot(age, ylab = "Age", xlab = "Year")

# now take care of NAs, count for each matrix
sapply(age,  function(x) sum(is.na(x)))

# investigate the 61 NAs in 2001
age2001 = age[["2001"]]

# explore original raw files, we dropped header in our latet file, so need to add index back in to offset
grep("^===", menFiles[['2001']])

badAgeIndex = which(is.na(age2001)) + 5
menFiles[['2001']][ badAgeIndex ]

# scattered throughout file
badAgeIndex

extractVariables = 
function(file, varNames =c("name", "home", "ag", "gun",
                           "net", "time"))
{
  
  # Find the index of the row with =s
  eqIndex = grep("^===", file)
  # Extract the two key rows and the data 
  spacerRow = file[eqIndex] 
  headerRow = tolower(file[ eqIndex - 1 ])
  body = file[ -(1 : eqIndex) ]
  # Remove footnotes and blank rows
  footnotes = grep("^[[:blank:]]*(\\*|\\#)", body)
  if ( length(footnotes) > 0 ) body = body[ -footnotes ]
  blanks = grep("^[[:blank:]]*$", body)
  if (length(blanks) > 0 ) body = body[ -blanks ]
  
  
  # Obtain the starting and ending positions of variables   
  searchLocs = findColLocs(spacerRow)
  locCols = selectCols(varNames, headerRow, searchLocs)
  
  Values = mapply(substr, list(body), start = locCols[1, ], 
                  stop = locCols[2, ])
  colnames(Values) = varNames
  
  return(Values)
}

menResMat = lapply(menFiles, extractVariables)
#womenResMat = lapply(womenFiles, extractVariables)

# address minimum age issues in 2001, 2002 and 2003
which(age2001 < 5)

# find lines corresponding to the indices, age shows zero, hold for analysis
menFiles[['2001']][ which(age2001 < 5) + 5 ]


# time variable creation
charTime = menResMat[['2012']][, 'time']
head(charTime, 5)

tail(charTime, 5)

# use str split on colons to piece them up
timePieces = strsplit(charTime, ":")

timePieces[[1]]

tail(timePieces, 1)

timePieces = sapply(timePieces, as.numeric)

# report time in minutes
runTime = sapply(timePieces, 
                 function(x) {
                   if (length(x) == 2) x[1] + x[2]/60
                   else 60*x[1] + x[2] + x[3]/60
                 })

summary(runTime)

# encapsulte into converTime
convertTime = function(time) {
  timePieces = strsplit(time, ":")
  timePieces = sapply(timePieces, as.numeric)
  sapply(timePieces, function(x) {
                      if (length(x) == 2) x[1] + x[2]/60
                      else 60*x[1] + x[2] + x[3]/60
                      })
}

# create final dataframe for analysis

createDF = 
function(Res, year, sex) 
{
  # Determine which time to use
  useTime = if( !is.na(Res[1, 'net']) )  
              Res[ , 'net']
            else if( !is.na(Res[1, 'gun']) ) 
               Res[ , 'gun']
            else 
               Res[ , 'time']

  # convert time to minutes
  runTime = convertTime(useTime)
  
  Results = data.frame(year = rep(year, nrow(Res)), # fill year into df
                       sex = rep(sex, nrow(Res)), # fill sex into df
                       name = Res[ , 'name'],
                       home = Res[ , 'home'],
                       age = as.numeric(Res[, 'ag']), 
                       runTime = runTime,
                       stringsAsFactors = FALSE)
  invisible(Results)
}

# create men's DF from each matrix
#menDF = mapply(createDF, menResMat, year = 1999:2012,
#               sex = rep("M", 14), SIMPLIFY = FALSE)
# more Nas from time being coerced to NA
#warnings()[ c(1:2, 49:50) ]

sapply(menDF, function(x) sum(is.na(x$runTime)))


# adjust for footnotes in run time and blanks
createDF = function(Res, year, sex) 
{
  # Determine which time to use
  if ( !is.na(Res[1, 'net']) ) useTime = Res[ , 'net']
  else if ( !is.na(Res[1, 'gun']) ) useTime = Res[ , 'gun']
  else useTime = Res[ , 'time']
  
  # Remove # and * and blanks from time
  useTime = gsub("[#\\*[:blank:]]", "", useTime)
  runTime = convertTime(useTime[ useTime != "" ])
  
  # Drop rows with no time
  Res = Res[ useTime != "", ]
  #if(sex=='W'){
  #  
  #  age = gsub("   ", "0  ", Res[,'ag'])
  #  age = gsub("XX "," 0 ", age)
  #  
  #  Res[, 'ag'] = age
  #}
  
  Results = data.frame(year = rep(year, nrow(Res)),
                       sex = rep(sex, nrow(Res)),
                       name = Res[ , 'name'], home = Res[ , 'home'],
                       age = as.numeric(Res[, 'ag']), 
                       runTime = runTime,
                       stringsAsFactors = FALSE)
  invisible(Results)
}

# still a lot of NAs from 2006 with incorrect spacer row!
#menDF = mapply(createDF, menResMat, year = 1999:2012,
#               sex = rep("M", 14), SIMPLIFY = FALSE)

#sapply(menDF, function(x) sum(is.na(x$runTime)))

# FIX 2006
separatorIdx = grep("^===", menFiles[["2006"]])
separatorRow = menFiles[['2006']][separatorIdx]
separatorRowX = paste(substring(separatorRow, 1, 63), " ", 
                      substring(separatorRow, 65, nchar(separatorRow)), 
                      sep = "")
menFiles[['2006']][separatorIdx] = separatorRowX

# FINALLY good to go
menResMat = sapply(menFiles, extractVariables)
menDF = mapply(createDF, menResMat, year = 1999:2012,
               sex = rep("M", 14), SIMPLIFY = FALSE)


# clean 2006 file with bad separator for women as well
separatorIdx = grep("^===", womenFiles[["2006"]])
separatorRow = womenFiles[['2006']][separatorIdx]
separatorRowX = paste(substring(separatorRow, 1, 63), " ", 
                      substring(separatorRow, 65, nchar(separatorRow)), 
                      sep = "")
womenFiles[['2006']][separatorIdx] = separatorRowX

womenResMat = sapply(womenFiles, extractVariables)

# women files have issues with ages of "XX" and "   ", adjusted previous create DF for this issue
womenDF = mapply(createDF, womenResMat, year = 1999:2012,
                 sex = rep("W", 14), SIMPLIFY = FALSE)

# womens files have some missing ages being coerced to NA. 
# Let's fix and insert zeros and take care of later in analysis
# initial analysis shows one age of XX in women's files, need to clean this as well
# implemented in createDF above
# lapply(womenDF, function(x) {x[!complete.cases(x),] })
# sapply(womenResMat, function(x){ sum(x[,'ag'] == "   ")})
# womenResMat[[4]][3261,]


#pdf("CB_BoxplotTimeByYr.pdf", width = 8, height = 5)
boxplot(sapply(menDF, function(x) x$runTime), 
        xlab = "Year", ylab = "Run Time (min)")
#dev.off()

cbMen = do.call(rbind, menDF)
save(cbMen, file = "cbMen.rda")

dim(cbMen)

load("cbMen.rda")

pdf("CB_Overplot.pdf", width = 8, height = 6)
oldPar = par(mar = c(4.1, 4.1, 1, 1))

```